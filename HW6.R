

# 1) Set up the environment by importing required libraries -- which will you need?

# 2) Read in the dataset (refer to the prior HW for how to read in a csv!)

# 3) Report the summary statistics (min, max, median, etc) of the numeric columns

# 4) Report some information on all the columns (number of nulls, for example). 
# In Python, we used .info() for this. 

# 5) Rename a column in the dataset

# 6) Count how many 2, 3, 4-bedroom houses are in the dataset

# 7) Plot a bar chart of the number of bedrooms in Seattle homes

# 8) What is the mean number of bedrooms? 

# 9) Subsetting and selecting rows: 
# Perhaps we're interested only in the data for houses with 4 or fewer bedrooms. 
# Perhaps homes with 5 or more bedrooms are quite different and 
# we're more interested in more typical homes. 
# Can we create a copy of the dataset with only homes with fewer than 5 bedrooms? 

# 10) Filter on multiple criteria
# You don't have to limit yourself to filtering on a single criteria. 
# Try it again, this time by combining any filtering criteria you'd 
# like (e.g. bathrooms < 3 or sqft_living > 500). You pick the criteria! 

# 11) Find null values for price_sold
# Are there any houses where the sold price is null? 

# 12) Create any groupby and apply any function (e.g. mean) you would like

# 13) Create a pairplot of the numeric columns in the dataset
# Refer to HW 4 for how to do a pairplot in R

# 14) OPTIONAL: Create a correlation heatmap 
# Correlation tells us how much two variables move in the same direction (or not). 
# Correlation is measured for each pair of columns/fields. 
# You can put this information in a table. 
# But a table of correlations has a lot of numbers and can be hard to interpret, 
# which is why a heatmap is commonly used. 
# The heatmap just turns the numbers in a correlation table into colors, 
# so that we can more quickly spot fields/columns that are highly correlated.


